# Machine Learning

### How can you reduce overfitting? {-}

- Collect more data to train with
- Use data augmentation to generate more train data
- Use cross-validation to better estimate your error during model selection
- Reduce the complexity of the model by reducing the number of parameters/layers
- Use a different model/architecture that generalises better
- Use a regularisation technique (L1/L2 regularisation, dropout)
- Use early stopping during training
- Filter out irrelevant or redundant features using a feature selection technique
- Use Ensembling to combine predictions from multiple models

### Define accuracy, precision, recall, specificity {-}

#### Accuracy {-}

$$
  \text{Accuracy} = \frac{TP + TN}{TP + FP + FN + TN}
$$

```{r accuracy-definition-diagram, echo=FALSE, fig.align="center", out.width = "80%"}
knitr::include_graphics("images/accuracy-definition-diagram.svg")
```

#### Precision {-}

$$
  \text{Precision} = \frac{TP}{TP + FP}
$$

```{r precision-definition-diagram, echo=FALSE, fig.align="center", out.width = "80%"}
knitr::include_graphics("images/precision-definition-diagram.svg")
```

#### Recall (Sensitivity) {-}

$$
  \text{Recall} = \frac{TP}{TP + FN}
$$

```{r recall-definition-diagram, echo=FALSE, fig.align="center", out.width = "80%"}
knitr::include_graphics("images/recall-definition-diagram.svg")
```

#### Specificity {-}

$$
  \text{Specificity} = \frac{TN}{TN + FP}
$$

```{r specificity-definition-diagram, echo=FALSE, fig.align="center", out.width = "80%"}
knitr::include_graphics("images/specificity-definition-diagram.svg")
```

### What are training, validation (development) and test sets? {-}

**Train (training) set** is a set of examples on which the model is trained.

**Validation set** or **dev (development) set** is a set of examples used for model selection and hyperparameter tuning. This is independent of the training set but it should come from the same distribution. The examples in this set are different from the ones seen by the models during training. Different trained models are all evaluated on the validation/dev set and the best performing model is chosen.

**Test set** is a set of examples that are used to assess the performance of the very final model on examples that have not used before either during training or model selection/hyperparameter tuning.

### What is the right split for train/dev/test sets? {-}

- For smaller datasets of up to 10K examples, the split is classically **60% (train) - 20% (dev) - 20% (test)**.
- For big datasets that typically contain millions of examples (used in training complex deep learning models), one can afford to do a split of **98% (train) - 1% (dev) - 1% (test)**. This maximises the amount of data needed for training the complex models, while still setting asside at least 10K of examples for each of the dev and test sets. 

### Define loss, cost and objective functions {-}

- Loss function is a function defined on a single example producing a single penalty term. It is a measure of error that tells us how good the prediction is compared to the actual label of the example.

- Cost function is evaluated on all the examples in a specific set (e.g. the train set for train error, the test set for test error, a mini-batch in mini-batch gradient descent), and it is typically a sum (or average) of the loss function over all examples. It might include additional penalty terms like regularisation terms. The ultimate goal of training a model is to minimise the cost function.

- Objective function is a function that measures the quality of a solution to a problem. One searches for optimal solutions to the problem by optimising the objective function, i.e. finding the parameters of the solution/model that minimise or maximise (depending on the problem) the objective function. The cost function is an example of an objective function.

### Place bayes/human error, training error and dev error on this graph. Define avoidable bias and variance on the same graph. {-}

```{r avoidable-bias-variance-definition-empty-graph, echo=FALSE, fig.align="center", out.width = "70%"}
knitr::include_graphics("images/avoidable-bias-variance-definition-empty-graph.svg")
```

Due to some degree of overfitting the train error is usually lower than the dev error. Assuming that for the specific domain the human error is a good proxy for the Bayes error, then this will be the lowest error possible and therefore the train error would be higher than that.


```{r avoidable-bias-variance-definition, echo=FALSE, fig.align="center", out.width = "70%"}
knitr::include_graphics("images/avoidable-bias-variance-definition.svg")
```

Avoidable bias is the difference between the human error and the train error. Variance is the difference between the train error and the dev error.

### Will you focus on reducing bias or variance in a neural network in the following cases and how?  {-}

|               |   Case 1   |  Case 2 |
| ------------- |:----------:|:-------:|
| Human error   |     2%     |   9.5%  |
| Train error   |    10%     |    10%  |
| Dev error     |    12%     |    12%  |

In case 1, the focus should be on reducing the bias. This can be achieved by

- training the network for longer,
- using a better optimisation algorithm (for example RMSprop or Adam),
- using a bigger network (more nodes per layer, more layers),
- changing to a different architecture that is better suited to the task.

In case 2, the focus should be on reducing the variance. This can be achieved by

- training with more data (either by collecting them, or by using data augmentation),
- using a regularisation techinque (for example dropout layers),
- changing to a different architecture that is better suited to the task.

