# Big Data

## Kafka

### What ordering guarantee Kafka provides and how can it be used? {-}

Kafka provides total order over records within a partition, while there are no guarantees for records spread accross different partitions. This guarantee is sufficient in many applications and can be leveraged by partitioning the records by the right key. For example, if records are partitioned by the user id, then ordering is preserved for all records for a specific user. As each partition is consumed by a single consumer, this guarantees that records for a specific user will be processed in the same order as they arrived.

### What is a consumer group? {-}

Consumer group is a group of application nodes that splits up the work of consuming messages. This provides the necessary parallelism in order to scale the application to high number of records. It is achieved by dividing up the partitions between the nodes so that every consumer gets a fair share of partitions. Membership in a consumer group is handled dynamically by the Kafka protocol.

### What is the maximum number of consumers that can consume in parallel from a given topic? {-}

As only one consumer can consume messages from a given partition, the maximum number of consumers is equal to the number of partitions for the topic. Extra consumers will be idle, but in some cases this might be desirable for failover.

### Explain event, ingestion and processing time and place them in chronological order {-}

**Event time** is a timestamp stored in the event itself and it is generated at the source of the event.

**Ingestion time** is the time when the event was stored on the topic. This timestamp is generated by the kafka broker that appends the event to a partition of the topic.

**Processing time** is the time when the event was processed by the application, usually a streaming application.

Assuming all clocks are accurate, the chronological order is

$$
  \text{Event time} \: < \: \text{Ingestion time} \: < \: \text{Processing time}.
$$
